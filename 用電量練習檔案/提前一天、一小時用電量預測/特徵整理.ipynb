{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf61e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import pearsonr\n",
    "import math\n",
    "\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn_rvm import EMRVC\n",
    "from sklearn_rvm import EMRVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c41218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## 在線使用設置##############\n",
    "# import plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.offline import iplot, init_notebook_mode\n",
    "# import plotly.express as px\n",
    "# import cufflinks as cf\n",
    "# from plotly.subplots import make_subplots\n",
    "# cf.go_offline()\n",
    "# cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "# import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65486216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# linear interpolation(線性插值)\n",
    "from scipy.interpolate import interp1d\n",
    "def interpolate(x, kind='linear'):\n",
    "    not_nan = np.logical_not(np.isnan(x))\n",
    "    indices = np.arange(len(x))\n",
    "#     interp = interp1d(indices[not_nan], x[not_nan], kind=kind)\n",
    "    interp = interp1d(indices[not_nan], x[not_nan], kind=kind,fill_value=\"extrapolate\")\n",
    "    return interp(indices) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029e052c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 評估績效\n",
    "def MAPE(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def nMAE(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs(y_true - y_pred))/y_true.mean() * 100\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48354b64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#日期轉換\n",
    "def transform_day_of_year(day_of_year):\n",
    "    if(day_of_year > 365):\n",
    "        return (day_of_year-356)/(538-356)\n",
    "    elif(day_of_year < 173):\n",
    "        return (day_of_year+365-356)/(538-356)\n",
    "    else:\n",
    "        return 1-((day_of_year-173)/(355-172))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b884d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#正規化\n",
    "def data_normalize(raw, need_normalize):\n",
    "    merge = raw.copy()\n",
    "    #使用最大最小值進行標準化\n",
    "    for i in range(len(need_normalize)):\n",
    "        column = need_normalize[i]\n",
    "        molecular = merge[column]-merge[column].min()\n",
    "        denominator = merge[column].max()-merge[column].min()\n",
    "        merge[column] = (molecular/denominator)\n",
    "    return merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1793bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#基本資料分割，依據天數\n",
    "def split_data_day(merge, rows, few):\n",
    "    row = rows.copy()\n",
    "    data_merge = merge.copy()\n",
    "    #print(data_merge)\n",
    "#    取提前一天的資料\n",
    "    day = rows['Date']-timedelta(days=few)\n",
    "    datas = data_merge[data_merge['Date'].isin(day)]\n",
    "    datas = datas[datas['Hour'].isin([row['Hour']])]\n",
    "    if (len(datas)== 0):\n",
    "        value = np.nan\n",
    "        return value\n",
    "    else:\n",
    "        value = datas['power'].values[0]\n",
    "        return value\n",
    "\n",
    "def split_data_persistence(merge, rows,pattern,isHoliday=False,time=0):\n",
    "    row = rows.copy()\n",
    "    data_merge = merge.copy()\n",
    "#     預測日為禮拜六時取前一個禮拜六，為國定假日時取過去最近一個禮拜日的資料，其餘使用提前一天的資料\n",
    "    if isHoliday:\n",
    "        if time ==0:\n",
    "            if row['Weekday'][0] == 1 or row['Weekday'][0] == 6:\n",
    "                day = rows['Date']-timedelta(days=7)\n",
    "                datas = data_merge[data_merge['Date'].isin(day)]\n",
    "                datas = datas[datas['Hour'].isin([row['Hour']])]\n",
    "    #         elif row['Weekday'][0]==7:\n",
    "    #             day = rows['Date']-timedelta(days=1)\n",
    "    #             datas = data_merge[data_merge['Date'].isin(day)]\n",
    "    #             datas = datas[datas['Hour'].isin([row['Hour']])]\n",
    "            elif row['isholiday'][0]==1 and row['Weekday'][0]!=6 and row['Weekday'][0]!=7:\n",
    "                row_date = rows['Date'].values[0]\n",
    "                datas = data_merge[data_merge['Date']<row_date]\n",
    "                datas = datas[datas['Weekday'].eq(7)]\n",
    "                datas = datas[datas['Hour'].isin([row['Hour']])].reset_index()\n",
    "                datas = datas.sort_values(by='TIME_TO_INTERVAL')\n",
    "                datas = datas.iloc[-1:]\n",
    "            else:\n",
    "                day = rows['Date']-timedelta(days=1)\n",
    "                datas = data_merge[data_merge['Date'].isin(day)]\n",
    "                datas = datas[datas['Hour'].isin([row['Hour']])]\n",
    "#         前一小時 time = 1 後一小時time = -1\n",
    "        else:\n",
    "           \n",
    "            if row['Weekday'][0] == 1 or row['Weekday'][0] == 6:\n",
    "                day = rows['Date']-timedelta(days=7)\n",
    "                datas = data_merge[data_merge['Date'].isin(day)]\n",
    "                datas = datas[datas['Hour'].isin([row['Hour']])]\n",
    "                index =  datas.index\n",
    "                datas =  data_merge.iloc[index-time]\n",
    "            elif row['isholiday'][0]==1 and row['Weekday'][0]!=6 and row['Weekday'][0]!=7:\n",
    "                row_date = rows['Date'].values[0]\n",
    "                datas = data_merge[data_merge['Date']<row_date]\n",
    "                datas = datas[datas['Weekday'].eq(7)]\n",
    "                datas = datas[datas['Hour'].isin([row['Hour']])].reset_index()\n",
    "                datas = datas.sort_values(by='TIME_TO_INTERVAL')\n",
    "                datas = datas.iloc[-1:]\n",
    "                datas = data_merge[data_merge['TIME_TO_INTERVAL'].isin(datas['TIME_TO_INTERVAL'])]\n",
    "                datas = datas[datas['Hour'].isin([row['Hour']])]\n",
    "                index =  datas.index\n",
    "                datas =  data_merge.iloc[index-time]\n",
    "            else:\n",
    "                day = rows['Date']-timedelta(days=1)\n",
    "                datas = data_merge[data_merge['Date'].isin(day)]\n",
    "                datas = datas[datas['Hour'].isin([row['Hour']])]\n",
    "                index =  datas.index\n",
    "                datas =  data_merge.iloc[index-time]\n",
    "                \n",
    "            \n",
    "    else:\n",
    "        if (pattern==0):\n",
    "            #周一和週六取前一個禮拜的資料，其餘取提前一天的資料\n",
    "            if row['Weekday'][0] == 1 or row['Weekday'][0] == 6:\n",
    "                day = rows['Date']-timedelta(days=7)\n",
    "                datas = data_merge[data_merge['Date'].isin(day)]\n",
    "                datas = datas[datas['Hour'].isin([row['Hour']])]\n",
    "            else:\n",
    "                day = rows['Date']-timedelta(days=1)\n",
    "                datas = data_merge[data_merge['Date'].isin(day)]\n",
    "                datas = datas[datas['Hour'].isin([row['Hour']])]\n",
    "        else:\n",
    "            #周一、周六、周日取前一個禮拜的資料，其餘取提前一天的資料\n",
    "            if row['Weekday'][0] == 1 or row['Weekday'][0] == 6 or row['Weekday'][0]==7:\n",
    "                day = rows['Date']-timedelta(days=7)\n",
    "                datas = data_merge[data_merge['Date'].isin(day)]\n",
    "                datas = datas[datas['Hour'].isin([row['Hour']])]\n",
    "            else:\n",
    "                day = rows['Date']-timedelta(days=1)\n",
    "                datas = data_merge[data_merge['Date'].isin(day)]\n",
    "                datas = datas[datas['Hour'].isin([row['Hour']])]\n",
    "    if (len(datas)== 0):\n",
    "        value = np.nan\n",
    "        return value\n",
    "    else:\n",
    "        value = datas['power'].values[0]\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eff916da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置輸入特徵\n",
    "def set_input(target_day, target_inps):\n",
    "\n",
    "# target_day: 預測天的資料(D+1)\n",
    "# target_inps: 預測天輸入的特徵值(D+1)\n",
    "\n",
    "#print(few_day[few_inps[0]].values)\n",
    "# 設置歷史資料輸入特徵\n",
    "# 設置預測天資料輸入特徵\n",
    "    if len(target_inps)>1:\n",
    "        target_features = np.concatenate((\n",
    "                            [target_day[target_inps[fea]].values for fea in range(len(target_inps))]\n",
    "                        ))\n",
    "    elif len(target_inps)==1:\n",
    "        target_features = target_day[target_inps[0]].values\n",
    "#     inputs = hourly_attribute\n",
    "#     return inputs\n",
    "    return target_features\n",
    "\n",
    "# 設置輸出特徵\n",
    "def set_output(target_day):\n",
    "    output = target_day['power'].values\n",
    "    return output\n",
    "\n",
    "# 設置預測天資訊\n",
    "def set_idx(target_day):\n",
    "    idx = {\n",
    "#             'TIME_TO_INTERVAL': target_day_time['TIME_TO_INTERVAL'].tolist()[2],\n",
    "        'TIME_TO_INTERVAL': target_day['TIME_TO_INTERVAL'].tolist()[0],\n",
    "        'power': target_day['power'].tolist()[0],\n",
    "        'isholiday' : target_day['isholiday'].tolist()[0],\n",
    "#         'dayOfYear_t': target_day['dayOfYear_t'].tolist()[0],\n",
    "    }\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "debe0e0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_build(train_x, train_y, train_idx, test_x, test_y, test_idx, model_name,scaler_x,scaler_y):\n",
    "    #模型訓練\n",
    "    if model_name == 'xgb':\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                        learning_rate=0.01, \n",
    "                        max_depth=1,\n",
    "                        colsample_bytree=0.1,\n",
    "                        reg_lambda=0.01,\n",
    "                        seed=1,\n",
    "                        subsample=0.1,\n",
    "                        min_child_weight=1,\n",
    "                        n_estimators=4000).fit(train_x, train_y)\n",
    "    elif model_name == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "               boosting_type='gbdt',\n",
    "                     verbose = 0,\n",
    "                     learning_rate = 0.01,\n",
    "                     num_leaves = 35,\n",
    "                     feature_fraction=0.8,\n",
    "                     bagging_fraction= 0.9,\n",
    "                     bagging_freq= 8,\n",
    "                     lambda_l1= 0.6,\n",
    "                     lambda_l2= 0).fit(train_x, train_y)\n",
    "    elif model_name == 'svr':\n",
    "        model = SVR(C=1, kernel=\"rbf\", gamma='auto').fit(train_x, train_y)\n",
    "    elif model_name == 'rvm':\n",
    "        model = EMRVR(kernel=\"rbf\", gamma='auto')\n",
    "        model.fit(train_x, train_y)\n",
    "    elif model_name == 'persistence':\n",
    "        test_x = scaler_x.inverse_transform(test_x)\n",
    "        test_idx['pred'] = test_x\n",
    "        test_idx['true'] = test_y\n",
    "        return test_idx\n",
    "\n",
    "\n",
    "\n",
    "#     other_params = {'learning_rate': 0.1, 'n_estimators': 500, 'max_depth': 5, 'min_child_weight': 1, 'seed': 0,\n",
    "#     'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "#     model = xgb.XGBRegressor(**other_params).fit(train_x, train_y)\n",
    "\n",
    "# 預測\n",
    "    pred_y = model.predict(test_x)\n",
    "    \n",
    "# 反正規劃\n",
    "    pred_y = pred_y.reshape(-1,1)\n",
    "    pred_y = scaler_y.inverse_transform(pred_y)\n",
    "    test_idx['pred'] = pred_y\n",
    "    test_idx['true'] = test_y\n",
    "    return test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3811f86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def performance(preds, columns):\n",
    "    mape, rmse, mae =  [], [], []\n",
    "    euclidean, pear =  [], []\n",
    "    for i in preds:\n",
    "        pred = preds[i].dropna()\n",
    "        mape.append(round(MAPE(pred['true'], pred[f'pred']),2))\n",
    "        rmse.append(round(RMSE(pred['true'], pred[f'pred']),2))\n",
    "        mae.append(round(nMAE(pred['true'], pred[f'pred']),2))\n",
    "#     #歐氏距離越大，兩個用戶相似度就越小\n",
    "#     euclidean.append(round(distance.euclidean(pred['true'], pred[f'pred']),2))\n",
    "#     pear.append(round(pearsonr(pred['true'], pred[f'pred'])[0],2))\n",
    "    \n",
    "    pred_result = pd.DataFrame({'feature': columns,\n",
    "              'P(RMSE)': rmse, 'P(MAPE)': mape, 'P(MAE)': mae, \n",
    "#                         'euclidean':euclidean, 'pearsonr': pear,\n",
    "#               'P(RMSE)': rmse, 'P(MAPE)': mape, 'P(MAE)': mae,\n",
    "             })\n",
    "    return pred_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17a67556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_oulier(total_data,merge, test_split_date):\n",
    "    total_data = total_data.copy()\n",
    "    data = merge.copy()\n",
    "    train_data = total_data[pd.to_datetime(total_data['Date'])<test_split_date]\n",
    "    \n",
    "    \n",
    "    re_before = len(data)\n",
    "    n=1.5\n",
    "    Q3 = np.percentile(train_data['power'],75) \n",
    "    Q1 = np.percentile(train_data['power'],25)\n",
    "    #IQR = Q3-Q1\n",
    "    IQR = Q3 - Q1 \n",
    "    \n",
    "    #outlier step\n",
    "    outlier_step = n * IQR\n",
    "    dq3 = data[~(data['power'] < Q3 + outlier_step)]\n",
    "    dq1 = data[~(data['power'] > Q1 - outlier_step)]\n",
    "    \n",
    "    outlier = pd.concat([dq3, dq1])\n",
    "#     print(f'3 : {dq3}')\n",
    "#     dq3['power'].iplot()\n",
    "#     print(f'1 : {dq1}')\n",
    "#     dq1['power'].iplot()\n",
    "\n",
    "    #outlier = Q3 + n*IQR \n",
    "    data=data[data['power'] < Q3 + outlier_step]\n",
    "    #outlier = Q1 - n*IQR \n",
    "    data=data[data['power'] > Q1 - outlier_step]\n",
    "\n",
    "\n",
    "#     outlier_ = data['power'].describe().T['75%']*1.5\n",
    "#     d0 = data[~(data['power'] >= 0)]\n",
    "#     d1 = data[~(data['power'] < outlier_)]\n",
    "#     print(len(d0), len(d1))\n",
    "#     outlier = pd.concat([d0, d1])\n",
    "#     data = data[data['power'] >= 0]\n",
    "#     data = data[data['power'] < outlier_]\n",
    "    \n",
    "    re_after = len(data)\n",
    "\n",
    "    print(f'移除前: {re_before}, 移除後: {re_after}, 共移除 {re_before-re_after} 筆') \n",
    "    print(f'IQR: {IQR}, Q3: {Q3}, Q1: {Q1}, outlier(1.5*IQR): {outlier_step}, Q3+outlier: { Q3 + outlier_step}, Q1-outlier: {Q1 - outlier_step}')\n",
    "    \n",
    "    \n",
    "#     return data, outlier\n",
    "    return data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38ea73d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#體感溫度計算\n",
    "def apparent_temperature(Tem,RH,V):\n",
    "    hpa = (float(RH)/100)*6.105*math.exp((17.27*float(Tem))/(237.7+float(Tem)))\n",
    "    #print(hpa)\n",
    "    AT = 1.07*float(Tem)+0.2*hpa-0.65*float(V)-2.7\n",
    "    #print(AT)\n",
    "    \n",
    "    return AT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55069d0c",
   "metadata": {},
   "source": [
    "# 正式開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7ffd1b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#抓取日歷國定假日\n",
    "import requests\n",
    "\n",
    "page = 0\n",
    "isHoliday = pd.DataFrame()\n",
    "while True:\n",
    "    url = f\"https://data.ntpc.gov.tw/api/datasets/308DCD75-6434-45BC-A95F-584DA4FED251/json?page={page}&size=1000\"\n",
    "    res = requests.get(url)\n",
    "    resJson = res.json()\n",
    "    resJson2 = pd.DataFrame(resJson)\n",
    "    isHoliday = pd.concat([isHoliday, resJson2])\n",
    "    page+=1\n",
    "    if resJson[-1]['date']>'2022':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23ffc589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "isHoliday['Date'] = pd.to_datetime(isHoliday['date'])\n",
    "isHoliday['isholiday']=isHoliday.apply(lambda row: 1 if row['isholiday']=='是' else 0, axis=1)\n",
    "#1為國定假日0則不是\n",
    "isHoliday = isHoliday[['Date','isholiday']]\n",
    "# isHoliday['Date'] = pd.to_datetime(isHoliday['Date'])\n",
    "isHoliday = isHoliday[isHoliday['Date']>='2022']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f5e1a3",
   "metadata": {},
   "source": [
    "# 特徵選擇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e071c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Hour = ['Hour_0.0', 'Hour_1.0', 'Hour_2.0', 'Hour_3.0', 'Hour_4.0', 'Hour_5.0',\n",
    "       'Hour_6.0', 'Hour_7.0', 'Hour_8.0', 'Hour_9.0', 'Hour_10.0',\n",
    "       'Hour_11.0', 'Hour_12.0', 'Hour_13.0', 'Hour_14.0', 'Hour_15.0',\n",
    "       'Hour_16.0', 'Hour_17.0', 'Hour_18.0', 'Hour_19.0', 'Hour_20.0',\n",
    "       'Hour_21.0', 'Hour_22.0', 'Hour_23.0']\n",
    "\n",
    "Dayofweek = ['Dayofweek_0.0', 'Dayofweek_1.0', 'Dayofweek_2.0', 'Dayofweek_3.0',\n",
    "       'Dayofweek_4.0', 'Dayofweek_5.0', 'Dayofweek_6.0']\n",
    "\n",
    "Isholiday = ['Isholiday_0', 'Isholiday_1']\n",
    "\n",
    "#few_input=['power']\n",
    "#target_input=['feel_temp']\n",
    "#target_input_2=['Hour', 'dayofweek', 'isholiday','feel_temp','pre_day_1','pre_day_7','pre_day_1_7_2','pre_day_1_7_3','pre_day_1_7_H']\n",
    "target_input_2=[ 'Hour','dayofweek','isholiday','feel_temp','RH','pre_day_1','pre_day_7','pre_day_1_7_2','pre_day_1_7_3']\n",
    "#target_input_2=['pre_day_7']\n",
    "# target_input=['Hour', 'dayofweek', 'isholiday']\n",
    "# neet_normalize = ['power', 'Hour', 'Month', 'Weekday', 'dayofweek', 'quarter', 'isholiday', 'temp', 'temp8', 'temp(cwb)']\n",
    "\n",
    "# neet_normalize = ['power', 'Hour', 'Month', 'dayofweek', 'quarter', 'isholiday', 'temp(ncue)', 'temp(cwb)']\n",
    "# neet_normalize = ['power', 'Hour', 'Month', 'dayofweek', 'quarter', 'isholiday', 'temp(cwb)']\n",
    "neet_normalize = ['power', 'Hour', 'dayofweek','feel_temp','RH','pre_day_1','pre_day_7','pre_day_1_7_2','pre_day_1_7_3','pre_day_1_7_H']\n",
    "#few_days_list = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51a73727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#設定輸出大小，以查看全部資料\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee92079f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "力行館\n",
      "     TIME_TO_INTERVAL  Year  Month       Date  Weekday  Day  Hour    power  \\\n",
      "0 2022-01-25 15:00:00  2022      1 2022-01-25        2   25    15  105.212   \n",
      "1 2022-01-25 16:00:00  2022      1 2022-01-25        2   25    16  102.321   \n",
      "2 2022-01-25 17:00:00  2022      1 2022-01-25        2   25    17   82.890   \n",
      "3 2022-01-25 18:00:00  2022      1 2022-01-25        2   25    18   82.032   \n",
      "4 2022-01-25 19:00:00  2022      1 2022-01-25        2   25    19   76.891   \n",
      "\n",
      "   dayofweek  isholiday  feel_temp  Temperature    RH  \n",
      "0          1          0       22.0         22.0  75.0  \n",
      "1          1          0       22.0         22.0  75.0  \n",
      "2          1          0       22.0         22.0  75.0  \n",
      "3          1          0        NaN          NaN   NaN  \n",
      "4          1          0        NaN          NaN   NaN  \n",
      "移除前: 1132, 移除後: 1068, 共移除 64 筆\n",
      "IQR: 21.310249999998845, Q3: 77.87249999999982, Q1: 56.56225000000097, outlier(1.5*IQR): 31.965374999998268, Q3+outlier: 109.83787499999809, Q1-outlier: 24.596875000002704\n",
      "len: 461, dropna len: 461\n",
      "len: 314, dropna len: 314\n",
      "工學院\n",
      "     TIME_TO_INTERVAL  Year  Month       Date  Weekday  Day  Hour    power  \\\n",
      "0 2022-01-04 19:00:00  2022      1 2022-01-04        2    4    19   978.54   \n",
      "1 2022-01-04 20:00:00  2022      1 2022-01-04        2    4    20  1014.96   \n",
      "2 2022-01-04 21:00:00  2022      1 2022-01-04        2    4    21   943.50   \n",
      "3 2022-01-04 22:00:00  2022      1 2022-01-04        2    4    22   905.98   \n",
      "4 2022-01-04 23:00:00  2022      1 2022-01-04        2    4    23   872.00   \n",
      "\n",
      "   dayofweek  isholiday  feel_temp  Temperature  RH  \n",
      "0          1          0        NaN          NaN NaN  \n",
      "1          1          0        NaN          NaN NaN  \n",
      "2          1          0        NaN          NaN NaN  \n",
      "3          1          0        NaN          NaN NaN  \n",
      "4          1          0        NaN          NaN NaN  \n",
      "移除前: 1460, 移除後: 1454, 共移除 6 筆\n",
      "IQR: 624.6125000000005, Q3: 800.1249999999997, Q1: 175.51249999999916, outlier(1.5*IQR): 936.9187500000007, Q3+outlier: 1737.0437500000003, Q1-outlier: -761.4062500000016\n",
      "len: 627, dropna len: 627\n",
      "len: 401, dropna len: 401\n",
      "教學一錧\n",
      "     TIME_TO_INTERVAL  Year  Month       Date  Weekday  Day  Hour  power  \\\n",
      "0 2022-01-04 19:00:00  2022      1 2022-01-04        2    4    19   15.2   \n",
      "1 2022-01-04 20:00:00  2022      1 2022-01-04        2    4    20   15.9   \n",
      "2 2022-01-04 21:00:00  2022      1 2022-01-04        2    4    21   14.4   \n",
      "3 2022-01-04 22:00:00  2022      1 2022-01-04        2    4    22   13.5   \n",
      "4 2022-01-04 23:00:00  2022      1 2022-01-04        2    4    23   14.5   \n",
      "\n",
      "   dayofweek  isholiday  feel_temp  Temperature  RH  \n",
      "0          1          0        NaN          NaN NaN  \n",
      "1          1          0        NaN          NaN NaN  \n",
      "2          1          0        NaN          NaN NaN  \n",
      "3          1          0        NaN          NaN NaN  \n",
      "4          1          0        NaN          NaN NaN  \n",
      "移除前: 1463, 移除後: 1242, 共移除 221 筆\n",
      "IQR: 2.9300000000000637, Q3: 16.36999999999999, Q1: 13.439999999999927, outlier(1.5*IQR): 4.3950000000000955, Q3+outlier: 20.765000000000086, Q1-outlier: 9.044999999999831\n",
      "len: 493, dropna len: 493\n",
      "len: 260, dropna len: 260\n",
      "管理學院經世館\n",
      "     TIME_TO_INTERVAL  Year  Month       Date  Weekday  Day  Hour    power  \\\n",
      "0 2022-01-04 19:00:00  2022      1 2022-01-04        2    4    19  231.985   \n",
      "1 2022-01-04 20:00:00  2022      1 2022-01-04        2    4    20  242.320   \n",
      "2 2022-01-04 21:00:00  2022      1 2022-01-04        2    4    21  165.420   \n",
      "3 2022-01-04 22:00:00  2022      1 2022-01-04        2    4    22  130.910   \n",
      "4 2022-01-04 23:00:00  2022      1 2022-01-04        2    4    23  117.675   \n",
      "\n",
      "   dayofweek  isholiday  feel_temp  Temperature  RH  \n",
      "0          1          0        NaN          NaN NaN  \n",
      "1          1          0        NaN          NaN NaN  \n",
      "2          1          0        NaN          NaN NaN  \n",
      "3          1          0        NaN          NaN NaN  \n",
      "4          1          0        NaN          NaN NaN  \n",
      "移除前: 1430, 移除後: 1362, 共移除 68 筆\n",
      "IQR: 43.67124999999737, Q3: 119.27374999999657, Q1: 75.6024999999992, outlier(1.5*IQR): 65.50687499999606, Q3+outlier: 184.78062499999263, Q1-outlier: 10.095625000003139\n",
      "len: 581, dropna len: 581\n",
      "len: 356, dropna len: 356\n",
      "第九宿舍\n",
      "     TIME_TO_INTERVAL  Year  Month       Date  Weekday  Day  Hour   power  \\\n",
      "0 2022-01-04 19:00:00  2022      1 2022-01-04        2    4    19  161.98   \n",
      "1 2022-01-04 20:00:00  2022      1 2022-01-04        2    4    20  204.26   \n",
      "2 2022-01-04 21:00:00  2022      1 2022-01-04        2    4    21  227.10   \n",
      "3 2022-01-04 22:00:00  2022      1 2022-01-04        2    4    22  209.88   \n",
      "4 2022-01-04 23:00:00  2022      1 2022-01-04        2    4    23  204.64   \n",
      "\n",
      "   dayofweek  isholiday  feel_temp  Temperature  RH  \n",
      "0          1          0        NaN          NaN NaN  \n",
      "1          1          0        NaN          NaN NaN  \n",
      "2          1          0        NaN          NaN NaN  \n",
      "3          1          0        NaN          NaN NaN  \n",
      "4          1          0        NaN          NaN NaN  \n",
      "移除前: 1542, 移除後: 1530, 共移除 12 筆\n",
      "IQR: 72.589999999997, Q3: 146.9549999999999, Q1: 74.3650000000029, outlier(1.5*IQR): 108.8849999999955, Q3+outlier: 255.8399999999954, Q1-outlier: -34.519999999992606\n",
      "len: 666, dropna len: 666\n",
      "len: 461, dropna len: 461\n",
      "第十宿舍\n",
      "     TIME_TO_INTERVAL  Year  Month       Date  Weekday  Day  Hour   power  \\\n",
      "0 2022-01-04 19:00:00  2022      1 2022-01-04        2    4    19  305.17   \n",
      "1 2022-01-04 20:00:00  2022      1 2022-01-04        2    4    20  360.16   \n",
      "2 2022-01-04 21:00:00  2022      1 2022-01-04        2    4    21  391.13   \n",
      "3 2022-01-04 22:00:00  2022      1 2022-01-04        2    4    22  404.83   \n",
      "4 2022-01-04 23:00:00  2022      1 2022-01-04        2    4    23  436.92   \n",
      "\n",
      "   dayofweek  isholiday  feel_temp  Temperature  RH  \n",
      "0          1          0        NaN          NaN NaN  \n",
      "1          1          0        NaN          NaN NaN  \n",
      "2          1          0        NaN          NaN NaN  \n",
      "3          1          0        NaN          NaN NaN  \n",
      "4          1          0        NaN          NaN NaN  \n",
      "移除前: 1644, 移除後: 1613, 共移除 31 筆\n",
      "IQR: 127.2550000000021, Q3: 269.2200000000013, Q1: 141.96499999999918, outlier(1.5*IQR): 190.88250000000315, Q3+outlier: 460.1025000000044, Q1-outlier: -48.91750000000397\n",
      "len: 720, dropna len: 720\n",
      "len: 579, dropna len: 579\n",
      "汙水處理廠\n",
      "     TIME_TO_INTERVAL  Year  Month       Date  Weekday  Day  Hour  power  \\\n",
      "0 2022-01-04 19:00:00  2022      1 2022-01-04        2    4    19  66.80   \n",
      "1 2022-01-04 20:00:00  2022      1 2022-01-04        2    4    20  68.16   \n",
      "2 2022-01-04 21:00:00  2022      1 2022-01-04        2    4    21  25.76   \n",
      "3 2022-01-04 22:00:00  2022      1 2022-01-04        2    4    22  28.80   \n",
      "4 2022-01-04 23:00:00  2022      1 2022-01-04        2    4    23  24.00   \n",
      "\n",
      "   dayofweek  isholiday  feel_temp  Temperature  RH  \n",
      "0          1          0        NaN          NaN NaN  \n",
      "1          1          0        NaN          NaN NaN  \n",
      "2          1          0        NaN          NaN NaN  \n",
      "3          1          0        NaN          NaN NaN  \n",
      "4          1          0        NaN          NaN NaN  \n",
      "移除前: 1463, 移除後: 1453, 共移除 10 筆\n",
      "IQR: 28.920000000002688, Q3: 57.96000000000117, Q1: 29.039999999998486, outlier(1.5*IQR): 43.38000000000403, Q3+outlier: 101.3400000000052, Q1-outlier: -14.340000000005546\n",
      "len: 629, dropna len: 629\n",
      "len: 414, dropna len: 414\n",
      "總變電站\n",
      "     TIME_TO_INTERVAL  Year  Month       Date  Weekday  Day  Hour   power  \\\n",
      "0 2022-01-04 19:00:00  2022      1 2022-01-04        2    4    19  483.70   \n",
      "1 2022-01-04 20:00:00  2022      1 2022-01-04        2    4    20  550.10   \n",
      "2 2022-01-04 21:00:00  2022      1 2022-01-04        2    4    21  542.04   \n",
      "3 2022-01-04 22:00:00  2022      1 2022-01-04        2    4    22  567.84   \n",
      "4 2022-01-04 23:00:00  2022      1 2022-01-04        2    4    23  609.90   \n",
      "\n",
      "   dayofweek  isholiday  feel_temp  Temperature  RH  \n",
      "0          1          0        NaN          NaN NaN  \n",
      "1          1          0        NaN          NaN NaN  \n",
      "2          1          0        NaN          NaN NaN  \n",
      "3          1          0        NaN          NaN NaN  \n",
      "4          1          0        NaN          NaN NaN  \n",
      "移除前: 1545, 移除後: 1540, 共移除 5 筆\n",
      "IQR: 153.44000000000153, Q3: 435.16000000000014, Q1: 281.7199999999986, outlier(1.5*IQR): 230.1600000000023, Q3+outlier: 665.3200000000024, Q1-outlier: 51.55999999999631\n",
      "len: 666, dropna len: 666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 453, dropna len: 453\n",
      "育成中心\n",
      "     TIME_TO_INTERVAL  Year  Month       Date  Weekday  Day  Hour  power  \\\n",
      "0 2022-01-04 19:00:00  2022      1 2022-01-04        2    4    19  15.49   \n",
      "1 2022-01-04 20:00:00  2022      1 2022-01-04        2    4    20  17.33   \n",
      "2 2022-01-04 21:00:00  2022      1 2022-01-04        2    4    21  17.33   \n",
      "3 2022-01-04 22:00:00  2022      1 2022-01-04        2    4    22  12.53   \n",
      "4 2022-01-04 23:00:00  2022      1 2022-01-04        2    4    23  12.66   \n",
      "\n",
      "   dayofweek  isholiday  feel_temp  Temperature  RH  \n",
      "0          1          0        NaN          NaN NaN  \n",
      "1          1          0        NaN          NaN NaN  \n",
      "2          1          0        NaN          NaN NaN  \n",
      "3          1          0        NaN          NaN NaN  \n",
      "4          1          0        NaN          NaN NaN  \n",
      "移除前: 1533, 移除後: 1523, 共移除 10 筆\n",
      "IQR: 3.3700000000003474, Q3: 13.690000000000511, Q1: 10.320000000000164, outlier(1.5*IQR): 5.055000000000521, Q3+outlier: 18.74500000000103, Q1-outlier: 5.264999999999643\n",
      "len: 667, dropna len: 667\n"
     ]
    }
   ],
   "source": [
    "data_name = ['力行館.csv', '工學院.csv', '教學一錧.csv', '管理學院經世館.csv', \n",
    "             '第九宿舍.csv', '第十宿舍.csv', \n",
    "             '汙水處理廠.csv', '總變電站.csv', '育成中心.csv']\n",
    "# data_name = ['力行館(temp).csv']\n",
    "log_datas = {}\n",
    "model_perf = {}\n",
    "test_split_date = pd.to_datetime('2022-05-01')\n",
    "\n",
    "for name in data_name:\n",
    "    print(name[:-4])\n",
    "    data_temp = pd.read_csv(f'./Dataset/20230118/merge/{name}')\n",
    "    Observatory = pd.read_csv(f'./Dataset/solar_汙水廠(history).csv')\n",
    "    data1 = data_temp.copy()\n",
    "    data2 = Observatory.copy()\n",
    "    #做欄位整理\n",
    "    data1['TIME_TO_INTERVAL'] = pd.to_datetime(data1['TIME_TO_INTERVAL'])\n",
    "    data2['TIME_TO_INTERVAL'] = pd.to_datetime(data2['TIME_TO_INTERVAL'])\n",
    "    data1['Date'] = data1['TIME_TO_INTERVAL'].dt.date\n",
    "    data1['Hour'] = data1['TIME_TO_INTERVAL'].dt.hour\n",
    "    data2['Date'] = data2['TIME_TO_INTERVAL'].dt.date\n",
    "    data2['Hour'] = data2['TIME_TO_INTERVAL'].dt.hour\n",
    "    data1.loc[data1['Hour']==0,'Hour']=24\n",
    "  \n",
    "    #轉換型態\n",
    "    data1['Date'] = data1['Date'].astype(str)\n",
    "    data2['Date'] = data2['Date'].astype(str)\n",
    "    #合併\n",
    "    data_merge = data1.merge(data2, how=\"left\",on=['Date','Hour'])\n",
    "    total_data = data_merge.copy()\n",
    "    data = data_merge.copy()\n",
    "    data = data.drop(\"TIME_TO_INTERVAL_y\", axis = 1)\n",
    "    data.rename(columns = {'TIME_TO_INTERVAL_x':'TIME_TO_INTERVAL'}, inplace = True)\n",
    "    data['Date'] = pd.to_datetime(data['TIME_TO_INTERVAL']).dt.date\n",
    "#     #只抓取>20220608的資料\n",
    "#     data = data[pd.to_datetime(data['Date']) >= pd.to_datetime('2022-06-08')]\n",
    "# #     print( pd.to_datetime(data['TIME_TO_INTERVAL']).dt.date[0])\n",
    "# #     data_start_date = pd.to_datetime(data['TIME_TO_INTERVAL']).dt.date[0]+datetime.timedelta(days=1)\n",
    "#     data_start_date = pd.to_datetime(data.head(1)['TIME_TO_INTERVAL']).dt.date+datetime.timedelta(days=1)\n",
    "#     print(type(data_start_date.values[0]))\n",
    "#     data = data[pd.to_datetime(data['Date']) >= pd.to_datetime('2022-06-09')]\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "    data['TIME_TO_INTERVAL'] = pd.to_datetime(data['TIME_TO_INTERVAL'])\n",
    "    data = data.sort_values(by='TIME_TO_INTERVAL')\n",
    "    data['Date'] = data['TIME_TO_INTERVAL'].dt.date\n",
    "    data['Hour'] = data['TIME_TO_INTERVAL'].dt.hour\n",
    "    data['Year'] = data['TIME_TO_INTERVAL'].dt.year\n",
    "    data['Month'] = data['TIME_TO_INTERVAL'].dt.month\n",
    "    data['Day'] = data['TIME_TO_INTERVAL'].dt.day\n",
    "    data['Weekday'] = data['TIME_TO_INTERVAL'].dt.weekday+1\n",
    "\n",
    "    data['dayOfYear'] = pd.to_datetime(data['Date']).dt.dayofyear\n",
    "    data['quarter'] = pd.to_datetime(data['Date']).dt.quarter\n",
    "    data['dayofweek'] = pd.to_datetime(data['Date']).dt.dayofweek\n",
    "    data['dayOfYear_t'] = data['dayOfYear'].apply(lambda DOY: transform_day_of_year(DOY))\n",
    "    data['dayOfYear'] = data['dayOfYear']/365\n",
    "    \n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    isHoliday['Date'] = pd.to_datetime(isHoliday['Date'])\n",
    "    data = pd.merge(data,isHoliday,on='Date',how='left')\n",
    "    data['isholiday'] = data.apply(lambda row: 1 if row['isholiday']==1 else 0, axis=1)\n",
    "    data = data.sort_values(by='TIME_TO_INTERVAL')\n",
    "    data = data[['TIME_TO_INTERVAL','Year','Month','Date','Weekday','Day','Hour','power','dayofweek','isholiday','ApparentTemperature(pred)[CWB]','Temperature(pred)[CWB]','RelativeHumidity(pred)[CWB]']]\n",
    "    #將體感溫度、溫度、濕度改名\n",
    "    data.rename(columns = {'ApparentTemperature(pred)[CWB]':'feel_temp'}, inplace = True)\n",
    "    data.rename(columns = {'Temperature(pred)[CWB]':'Temperature'}, inplace = True)\n",
    "    data.rename(columns = {'RelativeHumidity(pred)[CWB]':'RH'}, inplace = True)\n",
    "    \n",
    "    print(data.head(5))\n",
    "    #異常值移除\n",
    "    data = remove_oulier(total_data,data, test_split_date)\n",
    "    data = data.dropna().reset_index(drop=True)\n",
    "    print(f'len: {len(data)}, dropna len: {len(data.dropna())}')\n",
    "\n",
    "    \n",
    " \n",
    "    \n",
    "    pre_power = ['pre_day_1','pre_day_7','pre_day_1_7_2','pre_day_1_7_3','pre_day_1_7_H','pre_similarity','next_similarity']\n",
    "#     pre_power = ['pre_day_1_7_H']\n",
    "    for j in range(len(pre_power)):\n",
    "        pre_data_power=[]\n",
    "        for i in range(len(data)):\n",
    "            target_day = data.loc[i:i].reset_index(drop=True)\n",
    "            if(j==0):\n",
    "                few_day = split_data_day(data,target_day,1)\n",
    "                pre_data_power.append(few_day)\n",
    "            elif(j==1):\n",
    "                few_day = split_data_day(data,target_day,7)\n",
    "                pre_data_power.append(few_day)\n",
    "            elif(j==2):\n",
    "                few_day = split_data_persistence(data,target_day,0,isHoliday=False)\n",
    "                pre_data_power.append(few_day)\n",
    "            elif(j==3):\n",
    "                few_day = split_data_persistence(data,target_day,1,isHoliday=False)\n",
    "                pre_data_power.append(few_day)\n",
    "            elif(j==4):\n",
    "                few_day = split_data_persistence(data,target_day,0,isHoliday=True,time=0)\n",
    "                pre_data_power.append(few_day)\n",
    "            elif(j==5):\n",
    "                few_day = split_data_persistence(data,target_day,0,isHoliday=True,time = 1)\n",
    "                pre_data_power.append(few_day)\n",
    "            elif(j==6):\n",
    "                few_day = split_data_persistence(data,target_day,0,isHoliday=True,time = -1)\n",
    "                pre_data_power.append(few_day)\n",
    "          \n",
    "        data[pre_power[j]] = pre_data_power\n",
    "    data = data.dropna().reset_index(drop=True)\n",
    "    print(f'len: {len(data)}, dropna len: {len(data.dropna())}')\n",
    "    data.to_csv(f'./Dataset/20230118/final/{name}',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8965856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c30f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_name = ['力行館(temp).csv', '工學院(temp).csv', '教學一錧(temp).csv', '管理學院經世館(temp).csv', \n",
    "#               '第九宿舍(temp).csv', '第十宿舍(temp).csv', \n",
    "#               '汙水處理廠(temp).csv', '總變電站(temp).csv', '育成中心(temp).csv']\n",
    "data_name = ['力行館(temp).csv']\n",
    "test_split_date = pd.to_datetime('2022-05-01')\n",
    "for target in target_input_2:\n",
    "    log_datas = {}\n",
    "    target_input = ['pre_day_1']\n",
    "    target_input.append(target)\n",
    "    for name in data_name:\n",
    "        test_x, test_y, test_idx = [],[],[]\n",
    "        train_x, train_y, train_idx = [],[],[]\n",
    "        data = pd.read_csv(f'Dataset/merge/new/0727/{name}')\n",
    "        for i in range(len(data)):\n",
    "            target_day = data.loc[i:i].reset_index(drop=True)\n",
    "            target_day['TIME_TO_INTERVAL'] = pd.to_datetime(target_day['TIME_TO_INTERVAL'])\n",
    "            is_test_data = (target_day['TIME_TO_INTERVAL']>=test_split_date).values[0]\n",
    "            inputs = set_input(target_day, target_input)\n",
    "            output = set_output(target_day)\n",
    "            idx = set_idx(target_day)\n",
    "            if is_test_data:\n",
    "                test_x.append(inputs)\n",
    "                test_y.append(output)\n",
    "                test_idx.append(idx)\n",
    "            else:\n",
    "                train_x.append(inputs)\n",
    "                train_y.append(output)\n",
    "                train_idx.append(idx)\n",
    "    \n",
    "    #fit_transform 对数据先拟合 fit，找到数据的整体指标，如均值、方差、最大值最小值等，\n",
    "    #然后对数据集进行转换transform，从而实现数据的标准化、归一化操作。\n",
    "        scaler_x = MinMaxScaler()\n",
    "        scaler_x.fit(train_x)\n",
    "        train_x = scaler_x.transform(train_x)\n",
    "        test_x = scaler_x.transform(test_x)\n",
    "        scaler_y = MinMaxScaler()\n",
    "        scaler_y.fit(train_y)\n",
    "        train_y = scaler_y.transform(train_y)\n",
    "\n",
    "        train_x, train_y = np.array(train_x), np.array(train_y)\n",
    "        test_x, test_y = np.array(test_x), np.array(test_y)\n",
    "        train_idx, test_idx = pd.DataFrame(train_idx), pd.DataFrame(test_idx)   \n",
    "\n",
    "\n",
    "        #pred = model_build(train_x, train_y, train_idx, test_x, test_y, test_idx, 'persistence',scaler_x,scaler_y)\n",
    "        #pred = model_build(train_x, train_y, train_idx, test_x, test_y, test_idx, 'svr',scaler_x,scaler_y)\n",
    "        pred = model_build(train_x, train_y, train_idx, test_x, test_y, test_idx, 'rvm',scaler_x,scaler_y)\n",
    "        #pred = model_build(train_x, train_y, train_idx, test_x, test_y, test_idx, 'xgb',scaler_x,scaler_y)\n",
    "        #pred = model_build(train_x, train_y, train_idx, test_x, test_y, test_idx, 'lgb',scaler_x,scaler_y)\n",
    "\n",
    "        print(f'train: {len(train_idx)}, test: {len(test_idx)}')\n",
    "        log_datas[name[:-4]] = pred\n",
    "    result = performance(log_datas, data_name)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f74125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f0eab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dataframe->array\n",
    "performance(log_datas, data_name)\n",
    "\n",
    "# train_y = train_y * (target_max - target_min) + target_min\n",
    "# train_idx['power(n)'] = train_y\n",
    "# \t力行館(temp).csv\t10.46\t32.85\t28.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3557e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = test_idx\n",
    "test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b244a8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# import matplotlib.dates as md\n",
    "# data_name = ['力行館(temp).csv', '工學院(temp).csv', '教學一錧(temp).csv', '管理學院經世館(temp).csv', \n",
    "#               '第九宿舍(temp).csv', '第十宿舍(temp).csv', \n",
    "#               '汙水處理廠(temp).csv', '總變電站(temp).csv', '育成中心(temp).csv']\n",
    "# line_color = [\n",
    "#     '#1f77b4',  # muted blue\n",
    "#     '#ff7f0e',  # safety orange\n",
    "#     '#2ca02c',  # cooked asparagus green\n",
    "#     '#d62728',  # brick red\n",
    "#     '#9467bd',  # muted purple\n",
    "#     '#8c564b',  # chestnut brown\n",
    "#     '#e377c2',  # raspberry yogurt pink\n",
    "#     '#7f7f7f',  # middle gray\n",
    "#     '#bcbd22',  # curry yellow-green\n",
    "#     '#17becf'   # blue-teal\n",
    "# ]\n",
    "# i=-1\n",
    "# for name in data_name:\n",
    "#     i+=1\n",
    "#     merge_data = pd.read_csv(f'Dataset/merge/new/0727/{name}')\n",
    "#     data = merge_data.copy()\n",
    "#     xtick = int(len(data['TIME_TO_INTERVAL'])/72)\n",
    "\n",
    "#     fig_line = go.Figure()\n",
    "#     fig_line.add_trace(go.Scatter(y = data['power'], x=data['TIME_TO_INTERVAL'],\n",
    "#                         mode='lines',\n",
    "#                         name='真實值',\n",
    "#                         #line={'dash': 'dash'},\n",
    "#                         line_color= line_color[i]))\n",
    "#     # fig_line.add_trace(go.Scatter(y = data['power'], x=data['TIME_TO_INTERVAL'],\n",
    "#     #                     mode='lines',\n",
    "#     #                     name='預測值',\n",
    "#     #                     line_color= '#3498db'))\n",
    "#     fig_line.update_layout(\n",
    "#         yaxis_title='用電量/kWh',\n",
    "#         xaxis_title='Date',\n",
    "#         title=name,\n",
    "#         font=dict(\n",
    "#             size=18,\n",
    "#         ),\n",
    "#     #     yaxis2=dict(anchor='x', overlaying='y', side='right')\n",
    "#         height=450, \n",
    "#         width=1500,\n",
    "\n",
    "#     )\n",
    "\n",
    "#     fig_line.update_xaxes(nticks=xtick)\n",
    "\n",
    "\n",
    "#     #     fig_line.write_html(f'{folder_path}/img/{methods}_{i}.html')\n",
    "\n",
    "#     fig_line.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f2721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新舊資料相加\n",
    "# concate\n",
    "for filename in os.listdir(f\"./新資料\"): \n",
    "    sales1 =  pd.read_csv(f'./舊資料/{filename}')\n",
    "    sales2 =  pd.read_csv(f'./新資料/{filename}')\n",
    "    merge_data = pd.concat([sales1,sales2], axis=0, ignore_index=True)\n",
    "    print(merge_data.head(10))\n",
    "    print(merge_data.tail(10))\n",
    "    merge_data = merge_data.reset_index()\n",
    "    merge_data.to_csv(f'./final/{filename}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5a206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
